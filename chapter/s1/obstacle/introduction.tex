%###########################################################
%---------------------------------introduction--------------------------

\section{Introduction}

\subsection{Motivation}
\label{sec:ob_motivation}
Obstacle avoidance is fundamental for mobile robots in divers tasks, like cleaning, mining, and rescue, etc.
In this chapter, we deal with a classic task for a mobile robot equipped with a depth sensor: attempting to avoid collisions with obstacles while navigating in an unknown environment.
Using stereo vision systems or radar sensors as aids, researchers often build the geometry or topological mapping of environments \cite{liu2015incremental, liu2012markov} to make navigation decisions based on a global representation. Such methods regard the environment as a geometrical world and decisions are only made with preliminary features without an online learning process. Specific logic has to be particularly designed for different environments. It is still a challenge for mobile robots to rapidly adapt to a new environment. Active learning for mobile robots to achieve tasks have been widely achieved for mobile robot navigation tasks like localisation \cite{burgard1997active, singh2018active}. In this chapter, we aim for robots to actively learn essential features for obstacle avoidance.

Convolutional neural network (CNN), a typical model for deep-learning and cognitive recognition, are the state-of-the-art in computer vision tasks. The Success of type of hierarchical model also motivates robotics scientists to apply deep learning algorithms in common robotics problems like recognition and obstacle avoidance \cite{giusti2016machine, muller2005off, tai2016deep}.

As with most supervised learning algorithms, CNN extracts feature representations through training with a massive amount of labelled samples.
However, unlike typical computer vision tasks, robot navigation usually happens in dynamic environments with high probability and uncertainty. The overfitting problem of supervised learning limits the perception ability of hierarchical models for unseen inputs, and it is unrealistic for mobile robots to collect datasets covering all of the possible conditions. Besides this, the time-consuming work of dataset collection and labelling seriously influences the application of CNN-based learning methods. Another common problem is that robotics research usually considers the CNN mechanism as a black box. There lacks a proper metric to validate the efficiency of the network, let alone the improvement. In this chapter, we use receptive fields to visualize the salient regions that determine the output. This provides the ground for structure selection and performance justification.

Reinforcement learning is an efficient way to learn control policies without referencing the ground-truth. Combining reinforcement learning and hierarchical sensory processing, deep reinforcement learning (DRL) \cite{mnih2015human} can learn optimal policies directly from high-dimensional sensory inputs. And it has been shown to outperform all of the previous artificial control algorithms on Atari games \cite{mnih2013playing}.


We have proved the feasibility of a CNN-based supervised learning method for obstacle avoidance in an indoor environment \cite{tai2016deep, tai2017autonomous} and the effectiveness of the conventional reinforcement learning method in policy estimation \cite{tai2016mobile, tl_rcar_2016} through feature representations extracted from the pre-trained CNN model in \cite{tai2016deep}. In this chapter, we propose an end-to-end deep reinforcement learning method towards active obstacle avoidance in an unfamiliar environment by taking depth images as the input and control commands as the output. Unlike conventional learning methods, the training of deep reinforcement learning is a cognitive process.

\subsection{Contribution}
\label{sec:ob_contributions}
We stress the following contributions and features of this chapter:

\begin{itemize}

\item
By deep reinforcement learning, we show the developed obstacle avoidance capability of a mobile robot in unknown environments. We initialize the weights from a previous CNN model trained with real-world sensory samples and continually train it in an end-to-end manner. The performance is evaluated in both simulated and real-world environments.

\item The deep reinforcement learning model can quickly achieve obstacle avoidance ability in an indoor environment with several thousand training iterations, without additional man-made collection or labelling work for datasets.

\item For evaluations of the CNN, we use receptive fields in the original inputs to reason the feasibility of the trained model. The receptive fields activated by the final feature representations are presented through bilinear upsampling. The activation characters prove the cognitive ability improvement of hierarchical convolutional structures for
traversability estimation.

\end{itemize}
