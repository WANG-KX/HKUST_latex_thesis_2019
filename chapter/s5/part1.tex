\section{Part \ref{part1}: From Supervised Learning to Reinforcement Learning}
To begin, we visualized the advantages of feature evolution for obstacle avoidance from supervised learning to deep reinforcement learning through extracting the receptive field of convolutional neural networks. The objective of this part was to discuss the necessity of deep reinforcement learning except the powerful supervised learning.

The model of the deep reinforcement learning was initialized from a pre-trained supervised model. We conducted the learning process in a simulated indoor environment. When deploying the pre-trained supervised learning model, it could not be adapted to the new environment, which was quite different from the training dataset. However, reinforcement learning kept updating its performance and adaptability for this new environment. What more interesting is the perceptive field of the trained network for different input depth images. The supervised learning model seemed to extract the edge with a higher gradient of depth information. However, the reinforcement learning model finally learned the width feature of the traversable area, which is more meaningful for obstacle avoidance.

In general, the results presented in this part of the thesis show the on-line learning ability of deep reinforcement learning. The learned feature can also generalize to unseen depth samples from the real world.
